{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index Creation\n",
    "\n",
    "### TOC\n",
    "- [0️⃣ Initialize notebook variables](#0)\n",
    "- [1️⃣ Create an Azure AI Search index and load data](#1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "### 0️⃣ Initialize notebook variables\n",
    "\n",
    "- Resources will be suffixed by a unique string based on your subscription id.\n",
    "- Adjust the location parameters according your preferences and on the [product availability by Azure region.](https://azure.microsoft.com/explore/global-infrastructure/products-by-region/?cdn=disable&products=cognitive-services,api-management) \n",
    "- Adjust the OpenAI model and version according the [availability by region.](https://learn.microsoft.com/azure/ai-services/openai/concepts/models) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from azure.core.exceptions import ResourceExistsError\n",
    "from azure.identity import DefaultAzureCredential  \n",
    "from azure.search.documents.indexes import SearchIndexClient, SearchIndexerClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    AzureOpenAIEmbeddingSkill,\n",
    "    AzureOpenAIParameters,\n",
    "    AzureOpenAIVectorizer,\n",
    "    FieldMapping,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    HnswParameters,\n",
    "    IndexProjectionMode,\n",
    "    InputFieldMappingEntry,\n",
    "    OutputFieldMappingEntry,\n",
    "    SearchableField,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SearchIndex,\n",
    "    SearchIndexer,\n",
    "    SearchIndexerDataContainer,\n",
    "    SearchIndexerDataSourceConnection,\n",
    "    SearchIndexerDataSourceType,\n",
    "    SearchIndexerIndexProjections,\n",
    "    SearchIndexerIndexProjectionSelector,\n",
    "    SearchIndexerIndexProjectionsParameters,\n",
    "    SearchIndexerSkillset,\n",
    "    SemanticConfiguration,\n",
    "    SemanticField,\n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticSearch,\n",
    "    SimpleField,\n",
    "    SplitSkill,\n",
    "    VectorSearch,\n",
    "    VectorSearchAlgorithmMetric,\n",
    "    VectorSearchProfile,\n",
    ")\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "\n",
    "load_dotenv(override=True)\n",
    "azure_search_endpoint = os.getenv(\"AZURE_SEARCH_ENDPOINT\")\n",
    "azure_storage_connection_string = os.getenv(\"AZURE_STORAGE_CONNECTION_STRING\")\n",
    "azure_openai_embedding_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_openai_embedding_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL_NAME\")\n",
    "azure_openai_embedding_model = os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL_NAME\")\n",
    "azure_openai_api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_openai_embeddings_dimensions = 3072\n",
    "azure_storage_endpoint = f\"https://{os.getenv('AZURE_STORAGE_NAME')}.blob.core.windows.net\"\n",
    "PATH = \"../data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "### 1️⃣ Load data to Azure Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logger:\n",
    "        def info(self, msg, *args):\n",
    "            if args:\n",
    "                print(msg % args)\n",
    "            else:\n",
    "                print(msg)\n",
    "\n",
    "logger = Logger()\n",
    "\n",
    "def setup_index(azure_credential, index_name, azure_search_endpoint, azure_storage_connection_string, azure_storage_container ,azure_openai_embedding_endpoint, azure_openai_embedding_deployment, azure_openai_embedding_model, azure_openai_embeddings_dimensions):\n",
    "    index_client = SearchIndexClient(azure_search_endpoint, azure_credential)\n",
    "    indexer_client = SearchIndexerClient(azure_search_endpoint, azure_credential)\n",
    "\n",
    "    data_source_connections = indexer_client.get_data_source_connections()\n",
    "    if index_name in [ds.name for ds in data_source_connections]:\n",
    "        logger.info(f\"Data source connection {index_name} already exists, not re-creating\")\n",
    "    else:\n",
    "        logger.info(f\"Creating data source connection: {index_name}\")\n",
    "        indexer_client.create_data_source_connection(\n",
    "            data_source_connection=SearchIndexerDataSourceConnection(\n",
    "                name=index_name, \n",
    "                type=SearchIndexerDataSourceType.AZURE_BLOB,\n",
    "                connection_string=azure_storage_connection_string,\n",
    "                container=SearchIndexerDataContainer(name=azure_storage_container)))\n",
    "\n",
    "    index_names = [index.name for index in index_client.list_indexes()]\n",
    "    if index_name in index_names:\n",
    "        logger.info(f\"Index {index_name} already exists, not re-creating\")\n",
    "    else:\n",
    "        logger.info(f\"Creating index: {index_name}\")\n",
    "        index_client.create_index(\n",
    "            SearchIndex(\n",
    "                name=index_name,\n",
    "                fields=[\n",
    "                    SearchableField(name=\"chunk_id\", key=True, analyzer_name=\"keyword\", sortable=True),\n",
    "                    SimpleField(name=\"parent_id\", type=SearchFieldDataType.String, filterable=True),\n",
    "                    SearchableField(name=\"title\"),\n",
    "                    SearchableField(name=\"chunk\"),\n",
    "                    SearchField(\n",
    "                        name=\"text_vector\", \n",
    "                        type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                        vector_search_dimensions=azure_openai_embeddings_dimensions,\n",
    "                        vector_search_profile_name=\"vp\",\n",
    "                        stored=True,\n",
    "                        hidden=False)\n",
    "                ],\n",
    "                vector_search=VectorSearch(\n",
    "                    algorithms=[\n",
    "                        HnswAlgorithmConfiguration(name=\"algo\", parameters=HnswParameters(metric=VectorSearchAlgorithmMetric.COSINE))\n",
    "                    ],\n",
    "                    vectorizers=[\n",
    "                        AzureOpenAIVectorizer(\n",
    "                            name=\"openai_vectorizer\",\n",
    "                            azure_open_ai_parameters=AzureOpenAIParameters(\n",
    "                                api_key=azure_openai_api_key,\n",
    "                                resource_uri=azure_openai_embedding_endpoint,\n",
    "                                deployment_id=azure_openai_embedding_deployment,\n",
    "                                model_name=azure_openai_embedding_model\n",
    "                            )\n",
    "                        )\n",
    "                    ],\n",
    "                    profiles=[\n",
    "                        VectorSearchProfile(name=\"vp\", algorithm_configuration_name=\"algo\", vectorizer=\"openai_vectorizer\")\n",
    "                    ]\n",
    "                ),\n",
    "                semantic_search=SemanticSearch(\n",
    "                    configurations=[\n",
    "                        SemanticConfiguration(\n",
    "                            name=\"default\",\n",
    "                            prioritized_fields=SemanticPrioritizedFields(title_field=SemanticField(field_name=\"title\"), content_fields=[SemanticField(field_name=\"chunk\")])\n",
    "                        )\n",
    "                    ],\n",
    "                    default_configuration_name=\"default\"\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    skillsets = indexer_client.get_skillsets()\n",
    "    if index_name in [skillset.name for skillset in skillsets]:\n",
    "        logger.info(f\"Skillset {index_name} already exists, not re-creating\")\n",
    "    else:\n",
    "        logger.info(f\"Creating skillset: {index_name}\")\n",
    "        indexer_client.create_skillset(\n",
    "            skillset=SearchIndexerSkillset(\n",
    "                name=index_name,\n",
    "                skills=[\n",
    "                    SplitSkill(\n",
    "                        text_split_mode=\"pages\",\n",
    "                        context=\"/document\",\n",
    "                        maximum_page_length=2000,\n",
    "                        page_overlap_length=500,\n",
    "                        inputs=[InputFieldMappingEntry(name=\"text\", source=\"/document/content\")],\n",
    "                        outputs=[OutputFieldMappingEntry(name=\"textItems\", target_name=\"pages\")]),\n",
    "                    AzureOpenAIEmbeddingSkill(\n",
    "                        context=\"/document/pages/*\",\n",
    "                        resource_uri=azure_openai_embedding_endpoint,\n",
    "                        api_key=azure_openai_api_key,\n",
    "                        deployment_id=azure_openai_embedding_deployment,\n",
    "                        model_name=azure_openai_embedding_model,\n",
    "                        dimensions=azure_openai_embeddings_dimensions,\n",
    "                        inputs=[InputFieldMappingEntry(name=\"text\", source=\"/document/pages/*\")],\n",
    "                        outputs=[OutputFieldMappingEntry(name=\"embedding\", target_name=\"text_vector\")])\n",
    "                ],\n",
    "                index_projections=SearchIndexerIndexProjections(\n",
    "                    selectors=[\n",
    "                        SearchIndexerIndexProjectionSelector(\n",
    "                            target_index_name=index_name,\n",
    "                            parent_key_field_name=\"parent_id\",\n",
    "                            source_context=\"/document/pages/*\",\n",
    "                            mappings=[\n",
    "                                InputFieldMappingEntry(name=\"chunk\", source=\"/document/pages/*\"),\n",
    "                                InputFieldMappingEntry(name=\"text_vector\", source=\"/document/pages/*/text_vector\"),\n",
    "                                InputFieldMappingEntry(name=\"title\", source=\"/document/metadata_storage_name\")\n",
    "                            ]\n",
    "                        )\n",
    "                    ],\n",
    "                    parameters=SearchIndexerIndexProjectionsParameters(\n",
    "                        projection_mode=IndexProjectionMode.SKIP_INDEXING_PARENT_DOCUMENTS\n",
    "                    )\n",
    "                )))\n",
    "\n",
    "    indexers = indexer_client.get_indexers()\n",
    "    if index_name in [indexer.name for indexer in indexers]:\n",
    "        logger.info(f\"Indexer {index_name} already exists, not re-creating\")\n",
    "    else:\n",
    "        indexer_client.create_indexer(\n",
    "            indexer=SearchIndexer(\n",
    "                name=index_name,\n",
    "                data_source_name=index_name,\n",
    "                skillset_name=index_name,\n",
    "                target_index_name=index_name,        \n",
    "                field_mappings=[FieldMapping(source_field_name=\"metadata_storage_name\", target_field_name=\"title\")]\n",
    "            )\n",
    "        )\n",
    "\n",
    "def upload_documents(document_name, azure_credential, index_name, azure_search_endpoint, azure_storage_endpoint, azure_storage_container):\n",
    "    indexer_client = SearchIndexerClient(azure_search_endpoint, azure_credential)\n",
    "    # Upload the documents in /data folder to the blob storage container\n",
    "    blob_client = BlobServiceClient.from_connection_string(\n",
    "        azure_storage_connection_string, \n",
    "        credential=azure_credential\n",
    "    )\n",
    "    container_client = blob_client.get_container_client(azure_storage_container)\n",
    "    try:\n",
    "        container_client.create_container()\n",
    "    except ResourceExistsError:\n",
    "        pass\n",
    "    existing_blobs = [blob.name for blob in container_client.list_blobs()]\n",
    "\n",
    "    for file in os.scandir(PATH):\n",
    "        if file.name == document_name:\n",
    "            with open(file.path, \"rb\") as opened_file:\n",
    "                filename = os.path.basename(file.path)\n",
    "                # Check if blob already exists\n",
    "                if filename in existing_blobs:\n",
    "                    logger.info(\"Blob already exists, skipping file: %s\", filename)\n",
    "                else:\n",
    "                    logger.info(\"Uploading blob for file: %s\", filename)\n",
    "                    blob_client = container_client.upload_blob(filename, opened_file, overwrite=True)\n",
    "\n",
    "    # Start the indexer\n",
    "    try:\n",
    "        indexer_client.run_indexer(index_name)\n",
    "        logger.info(\"Indexer started. Any unindexed blobs should be indexed in a few minutes, check the Azure Portal for status.\")\n",
    "    except ResourceExistsError:\n",
    "        logger.info(\"Indexer already running, not starting again\")\n",
    "\n",
    "\n",
    "def create_container_for_each_index(azure_credential, index_name, azure_storage_connection_string):\n",
    "    # Create a blob container for each index\n",
    "    container_name = f\"{index_name}-container\"\n",
    "    blob_client = BlobServiceClient.from_connection_string(\n",
    "        azure_storage_connection_string, \n",
    "        credential=azure_credential\n",
    "    )\n",
    "    try:\n",
    "        container_client = blob_client.create_container(name=container_name)\n",
    "    except ResourceExistsError:\n",
    "        print('A container with this name already exists')\n",
    "        pass\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up index for score\n",
      "Index for score setup complete\n",
      "Setting up index for dividas\n",
      "Index for dividas setup complete\n",
      "Setting up index for cartaowill\n",
      "Index for cartaowill setup complete\n",
      "Setting up index for cartaosantander\n",
      "Index for cartaosantander setup complete\n",
      "Setting up index for cartaopicpay\n",
      "Index for cartaopicpay setup complete\n",
      "Setting up index for cartaoneon\n",
      "Index for cartaoneon setup complete\n",
      "Setting up index for cartaoitau\n",
      "Index for cartaoitau setup complete\n",
      "Setting up index for cartaodm\n",
      "Index for cartaodm setup complete\n",
      "Setting up index for cartaodigio\n",
      "Index for cartaodigio setup complete\n"
     ]
    }
   ],
   "source": [
    "azure_credential = DefaultAzureCredential()\n",
    "\n",
    "index_dict = {\n",
    "    \"score\": \"Score.pdf\",\n",
    "    \"dividas\": \"Dividas.md\",\n",
    "    \"cartaowill\": \"CartaoWill.md\",\n",
    "    \"cartaosantander\": \"CartaoSantander.md\",\n",
    "    \"cartaopicpay\": \"CartaoPicPay.md\",\n",
    "    \"cartaoneon\": \"CartaoNeon.md\",\n",
    "    \"cartaoitau\": \"CartaoItau.md\",\n",
    "    \"cartaodm\": \"CartaoDm.md\",\n",
    "    \"cartaodigio\": \"CartaoDigio.md\"\n",
    "}\n",
    "\n",
    "# Loop through the dictionary and create an index for each entry\n",
    "for index_name, document_name in index_dict.items():\n",
    "    logger.info(f\"Setting up index for {index_name}\")\n",
    "\n",
    "    create_container_for_each_index(\n",
    "        azure_credential, \n",
    "        index_name, \n",
    "        azure_storage_connection_string\n",
    "    )\n",
    "\n",
    "    setup_index(azure_credential,\n",
    "        index_name, \n",
    "        azure_search_endpoint,\n",
    "        azure_storage_connection_string,\n",
    "        f\"{index_name}-container\",\n",
    "        azure_openai_embedding_endpoint,\n",
    "        azure_openai_embedding_deployment,\n",
    "        azure_openai_embedding_model,\n",
    "        azure_openai_embeddings_dimensions\n",
    "    )\n",
    "\n",
    "    upload_documents(document_name, azure_credential,\n",
    "        index_name,\n",
    "        azure_search_endpoint,\n",
    "        azure_storage_endpoint,\n",
    "        f\"{index_name}-container\"\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"Index for {index_name} setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
